{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assigment, we will work with the *Adult* data set. Please download the data from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/2/adult). Extract the data files into the subdirectory: `../05_src/data/adult/` (relative to `./05_src/`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "Assuming that the files `adult.data` and `adult.test` are in `../05_src/data/adult/`, then you can use the code below to load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "    'native-country', 'income'\n",
    "]\n",
    "adult_dt = (pd.read_csv('../../05_src/data/adult/adult.data', header = None, names = columns)\n",
    "              .assign(income = lambda x: (x.income.str.strip() == '>50K')*1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "\n",
       "        marital-status          occupation    relationship    race    sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White   Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White   Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White   Male   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States       0  \n",
       "1             0             0              13   United-States       0  \n",
       "2             0             0              40   United-States       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_dt.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get X and Y\n",
    "\n",
    "Create the features data frame and target data:\n",
    "\n",
    "+ Create a dataframe `X` that holds the features (all columns that are not `income`).\n",
    "+ Create a dataframe `Y` that holds the target data (`income`).\n",
    "+ From `X` and `Y`, obtain the training and testing data sets:\n",
    "\n",
    "    - Use a train-test split of 70-30%. \n",
    "    - Set the random state of the splitting function to 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adult_dt.drop(columns=['income'])\n",
    "Y = adult_dt['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (22792, 14)\n",
      "X_test shape: (9769, 14)\n",
      "Y_train shape: (22792,)\n",
      "Y_test shape: (9769,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, random_state=42)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")\n",
    "print(f\"Y_test shape: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random States\n",
    "\n",
    "Please comment: \n",
    "\n",
    "+ What is the [random state](https://scikit-learn.org/stable/glossary.html#term-random_state) of the [splitting function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)? \n",
    "+ Why is it [useful](https://en.wikipedia.org/wiki/Reproducibility)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting the random_state, you make sure that every time you split the data, you get the same training and testing sets. This is crucial for experiments where you want consistent and comparable results.Besides, if you're testing different models or algorithms on the same data, using the same random_state allows you to compare their performance fairly since they are trained and evaluated on the same subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "Create a [Column Transformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) that treats the features as follows:\n",
    "\n",
    "- Numerical variables\n",
    "\n",
    "    * Apply [KNN-based imputation for completing missing values](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html):\n",
    "        \n",
    "        + Consider the 7 nearest neighbours.\n",
    "        + Weight each neighbour by the inverse of its distance, causing closer neigbours to have more influence than more distant ones.\n",
    "    * [Scale features using statistics that are robust to outliers](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler).\n",
    "\n",
    "- Categorical variables: \n",
    "    \n",
    "    * Apply a [simple imputation strategy](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer):\n",
    "\n",
    "        + Use the most frequent value to complete missing values, also called the *mode*.\n",
    "\n",
    "    * Apply [one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html):\n",
    "        \n",
    "        + Handle unknown labels if they exist.\n",
    "        + Drop one column for binary variables.\n",
    "    \n",
    "    \n",
    "The column transformer should look like this:\n",
    "\n",
    "![](./images/assignment_2__column_transformer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education-num   32561 non-null  int64 \n",
      " 5   marital-status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital-gain    32561 non-null  int64 \n",
      " 11  capital-loss    32561 non-null  int64 \n",
      " 12  hours-per-week  32561 non-null  int64 \n",
      " 13  native-country  32561 non-null  object\n",
      " 14  income          32561 non-null  int32 \n",
      "dtypes: int32(1), int64(6), object(8)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "adult_dt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformers for numerical and categorical columns\n",
    "num_transforms = Pipeline(steps=[\n",
    "    ('knn_imputer', KNNImputer(n_neighbors=7, weights='distance')),\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "cat_transforms = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore', drop='if_binary'))\n",
    "])\n",
    "\n",
    "# Define the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num_transforms', num_transforms, ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']),\n",
    "    ('cat_transforms', cat_transforms, ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnTransformer(transformers=[('num_transforms',\n",
      "                                 Pipeline(steps=[('knn_imputer',\n",
      "                                                  KNNImputer(n_neighbors=7,\n",
      "                                                             weights='distance')),\n",
      "                                                 ('scaler', RobustScaler())]),\n",
      "                                 ['age', 'fnlwgt', 'education-num',\n",
      "                                  'capital-gain', 'capital-loss',\n",
      "                                  'hours-per-week']),\n",
      "                                ('cat_transforms',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('one_hot_encoder',\n",
      "                                                  OneHotEncoder(drop='if_binary',\n",
      "                                                                handle_unknown='ignore'))]),\n",
      "                                 ['workclass', 'education', 'marital-status',\n",
      "                                  'occupation', 'relationship', 'race', 'sex',\n",
      "                                  'native-country'])])\n"
     ]
    }
   ],
   "source": [
    "# Check the created ColumnTransformer\n",
    "print(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipeline\n",
    "\n",
    "Create a [model pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html): \n",
    "\n",
    "+ Add a step labelled `preprocessing` and assign the Column Transformer from the previous section.\n",
    "+ Add a step labelled `classifier` and assign a [`RandomForestClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to it.\n",
    "\n",
    "The pipeline looks like this:\n",
    "\n",
    "![](./images/assignment_2__pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(transformers=[('num_transforms',\n",
      "                                                  Pipeline(steps=[('knn_imputer',\n",
      "                                                                   KNNImputer(n_neighbors=7,\n",
      "                                                                              weights='distance')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   RobustScaler())]),\n",
      "                                                  ['age', 'fnlwgt',\n",
      "                                                   'education-num',\n",
      "                                                   'capital-gain',\n",
      "                                                   'capital-loss',\n",
      "                                                   'hours-per-week']),\n",
      "                                                 ('cat_transforms',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('one_hot_encoder',\n",
      "                                                                   OneHotEncoder(drop='if_binary',\n",
      "                                                                                 handle_unknown='ignore'))]),\n",
      "                                                  ['workclass', 'education',\n",
      "                                                   'marital-status',\n",
      "                                                   'occupation', 'relationship',\n",
      "                                                   'race', 'sex',\n",
      "                                                   'native-country'])])),\n",
      "                ('classifier', RandomForestClassifier())])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the final model pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),  # The ColumnTransformer from the previous step\n",
    "    ('classifier', RandomForestClassifier())  # The classifier step\n",
    "])\n",
    "\n",
    "# Check the created pipeline\n",
    "print(model_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation\n",
    "\n",
    "Evaluate the model pipeline using [`cross_validate()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html):\n",
    "\n",
    "+ Measure the following [preformance metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values): negative log loss, ROC AUC, accuracy, and balanced accuracy.\n",
    "+ Report the training and validation results. \n",
    "+ Use five folds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hossein-Bg\\anaconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [7] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "c:\\Users\\Hossein-Bg\\anaconda3\\envs\\dsi_participant\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:242: UserWarning: Found unknown categories in columns [7] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg_log_loss:\n",
      "  Training: -0.0817 ± 0.0002\n",
      "  Validation: -0.3698 ± 0.0219\n",
      "\n",
      "roc_auc:\n",
      "  Training: 1.0000 ± 0.0000\n",
      "  Validation: 0.9036 ± 0.0022\n",
      "\n",
      "accuracy:\n",
      "  Training: 1.0000 ± 0.0000\n",
      "  Validation: 0.8535 ± 0.0033\n",
      "\n",
      "balanced_accuracy:\n",
      "  Training: 1.0000 ± 0.0000\n",
      "  Validation: 0.7757 ± 0.0038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "# Specify the scoring metrics\n",
    "scoring_metrics = ['neg_log_loss', 'roc_auc', 'accuracy', 'balanced_accuracy']\n",
    "\n",
    "# Perform cross-validation with 5 folds\n",
    "cv_results = cross_validate(\n",
    "    model_pipeline, X_train, Y_train,\n",
    "    cv=5, scoring=scoring_metrics,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Report the training and validation results\n",
    "for metric in scoring_metrics:\n",
    "    print(f\"{metric}:\")\n",
    "    print(f\"  Training: {np.mean(cv_results[f'train_{metric}']):.4f} ± {np.std(cv_results[f'train_{metric}']):.4f}\")\n",
    "    print(f\"  Validation: {np.mean(cv_results[f'test_{metric}']):.4f} ± {np.std(cv_results[f'test_{metric}']):.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the fold-level results as a pandas data frame and sorted by negative log loss of the test (validation) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train_neg_log_loss  test_neg_log_loss  train_roc_auc  test_roc_auc  \\\n",
      "4           -0.082062          -0.401103            1.0      0.901449   \n",
      "2           -0.081506          -0.381763            1.0      0.901781   \n",
      "1           -0.081659          -0.367658            1.0      0.902183   \n",
      "3           -0.081985          -0.363595            1.0      0.906795   \n",
      "0           -0.081461          -0.334632            1.0      0.905621   \n",
      "\n",
      "   train_accuracy  test_accuracy  train_balanced_accuracy  \\\n",
      "4             1.0       0.855200                      1.0   \n",
      "2             1.0       0.854103                      1.0   \n",
      "1             1.0       0.847774                      1.0   \n",
      "3             1.0       0.857613                      1.0   \n",
      "0             1.0       0.852819                      1.0   \n",
      "\n",
      "   test_balanced_accuracy  \n",
      "4                0.777356  \n",
      "2                0.777248  \n",
      "1                0.768607  \n",
      "3                0.779872  \n",
      "0                0.775625  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract fold-level results and organize them into a DataFrame\n",
    "fold_results = pd.DataFrame(cv_results)\n",
    "\n",
    "# Sort the DataFrame by the negative log loss of the test set (ascending)\n",
    "fold_results_sorted = fold_results.sort_values(by='test_neg_log_loss', ascending=True)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(fold_results_sorted[['train_neg_log_loss', 'test_neg_log_loss', 'train_roc_auc', 'test_roc_auc',\n",
    "                           'train_accuracy', 'test_accuracy', 'train_balanced_accuracy', 'test_balanced_accuracy']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the mean of each metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of each metric:\n",
      "train_neg_log_loss        -0.081734\n",
      "test_neg_log_loss         -0.369750\n",
      "train_roc_auc              1.000000\n",
      "test_roc_auc               0.903566\n",
      "train_accuracy             1.000000\n",
      "test_accuracy              0.853502\n",
      "train_balanced_accuracy    1.000000\n",
      "test_balanced_accuracy     0.775742\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of each metric across folds\n",
    "metric_means = fold_results.mean()\n",
    "\n",
    "# Display the mean for each metric\n",
    "print(\"Mean of each metric:\")\n",
    "print(metric_means[['train_neg_log_loss', 'test_neg_log_loss', \n",
    "                    'train_roc_auc', 'test_roc_auc', \n",
    "                    'train_accuracy', 'test_accuracy', \n",
    "                    'train_balanced_accuracy', 'test_balanced_accuracy']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the same performance metrics (negative log loss, ROC AUC, accuracy, and balanced accuracy) using the testing data `X_test` and `Y_test`. Display results as a dictionary.\n",
    "\n",
    "*Tip*: both, `roc_auc()` and `neg_log_loss()` will require prediction scores from `pipe.predict_proba()`. However, for `roc_auc()` you should only pass the last column `Y_pred_proba[:, 1]`. Use `Y_pred_proba` with `neg_log_loss()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance metrics:\n",
      "{'neg_log_loss': -0.3842871640537188, 'roc_auc': 0.9003313166234516, 'accuracy': 0.8548469648889344, 'balanced_accuracy': 0.7748129514627378}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# Fit the model pipeline on the training data\n",
    "model_pipeline.fit(X_train, Y_train)\n",
    "\n",
    "# Generate predictions and prediction probabilities on the test set\n",
    "Y_pred = model_pipeline.predict(X_test)\n",
    "Y_pred_proba = model_pipeline.predict_proba(X_test)\n",
    "\n",
    "# Calculate the performance metrics\n",
    "test_metrics = {\n",
    "    'neg_log_loss': -log_loss(Y_test, Y_pred_proba),\n",
    "    'roc_auc': roc_auc_score(Y_test, Y_pred_proba[:, 1]),\n",
    "    'accuracy': accuracy_score(Y_test, Y_pred),\n",
    "    'balanced_accuracy': balanced_accuracy_score(Y_test, Y_pred)\n",
    "}\n",
    "\n",
    "# Display results as a dictionary\n",
    "print(\"Testing performance metrics:\")\n",
    "print(test_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Recoding\n",
    "\n",
    "In the first code chunk of this document, we loaded the data and immediately recoded the target variable `income`. Why is this [convenient](https://scikit-learn.org/stable/modules/model_evaluation.html#binary-case)?\n",
    "\n",
    "The specific line was:\n",
    "\n",
    "```\n",
    "adult_dt = (pd.read_csv('../05_src/data/adult/adult.data', header = None, names = columns)\n",
    "              .assign(income = lambda x: (x.income.str.strip() == '>50K')*1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Recoding the target variable income from a categorical format ('>50K' and '<=50K') to a binary format (1 and 0) simplifies the subsequent analysis and model training processes. Many machine learning algorithms expect numerical targets, so converting the target to a binary format upfront reduces the need for this step later.\n",
    "\n",
    " Assigning the transformed income column immediately as the data is loaded means that the resulting DataFrame is ready for model training and evaluation without additional preprocessing. This saves time and keeps the data preparation steps more readable and organized.\n",
    "\n",
    " Using a lambda function within assign() keeps the recoding step compact and easy to understand. It clearly shows that the income variable is being recoded as a binary variable where '>50K' becomes 1 (high income) and '<=' becomes 0 (low income)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "The [rubric](./assignment_2_rubric_clean.xlsx) contains the criteria for assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "🚨 **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** 🚨 for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-2`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_2.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "Becker,Barry and Kohavi,Ronny. (1996). Adult. UCI Machine Learning Repository. https://doi.org/10.24432/C5XW20."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
